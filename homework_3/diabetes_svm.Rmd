---
title: "Predicting Diabetes with Support Vector Machines"
author: "Cliff Lee"
date: "2023-11-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(datasets)
library(caret)
library(e1071)
library(kernlab)
library(pROC)
library(performanceEstimation)
library(ggplot2)
library(GGally)
library(kernlab)
library(tidymodels)
library(doParallel)
library(Metrics)
library(ROCR)


```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
  }


```


```{r, warning=FALSE, message=FALSE}
data <- read_csv('diabetes.csv', col_types="nnnnnnnnf")
data <- smote(Outcome ~ ., data, perc.over = 1.5, perc.under = 2.0)
data_2 <- as.data.frame(lapply(data[1:8], min_max_norm))
data <- cbind(data_2, data$`Outcome`)
colnames(data) <- c(colnames(data_2), 'Outcome')
```

### normalize
```{r, echo=FALSE, warning=FALSE, message=FALSE}
summary(data)
```
```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width="90%"}
#numeric_data <- data %>% dplyr::select(where(is.numeric))
ggpairs(data) 
```

```{r}

set.seed(1234)

sample_set <- sample(nrow(data), round(nrow(data)*0.80), replace = FALSE)

data_train <- data[sample_set,]
data_test <- data[-sample_set,]
```

## Overlap

```{r, echo=FALSE, warning=FALSE, message=FALSE}
plot(x=data_test$BMI, y=data_test$Pregnancies, col=data_test$Outcome, pch=19, cex=1.5)
```


## Regression

```{r, warning=FALSE, message=FALSE}
# REference: https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html
modelsvm <- svm(Pregnancies ~ Age, data_train)
predict_pregnancies <- predict(modelsvm, data_test)
p <- plot(x=data_test$Age, y=data_test$Pregnancies, main="SVM Regression Example #1",
          xlab="Scaled Age", ylab="Scaled Pregnancies")
points(data_test$Age, predict_pregnancies, col='red', pch=16)
legend("topright",legend=c("Regression", "Datapoint"),
       col=c("red", "black"), pch = c(16,1), bty="n")
```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
rmse_pregnancies <- rmse(data_test$Pregnancies, predict_pregnancies)
paste0("The root mean square error for predicted pregnancies is: " , round(rmse_pregnancies * 100,0), "%.")
```

```{r}
modelsvm <- svm(BloodPressure ~ SkinThickness, data_train)
predict_BloodPressure <- predict(modelsvm, data_test)
plot(x=data_test$SkinThickness, y=data_test$BloodPressure,
     main="SVM Regression Example #2",
          xlab="Scaled Skin Thickness", ylab="Scaled Blood Pressure")
points(data_test$SkinThickness, predict_BloodPressure, col='red', pch=16)
legend("bottomright",legend=c("Regression", "Datapoint"),
       col=c("red", "black"), pch = c(16,1), bty="n")

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
rmse_BloodPressure <- rmse(data_test$BloodPressure, predict_BloodPressure)
paste0("The root mean square error for predicted pregnancies is: " , round(rmse_BloodPressure * 100,0), "%.")
```


```{r, warning=FALSE, message=FALSE}
svm_linear <- svm(Outcome ~., data=data_train, kernel="linear", cost=5)
r <- predict(svm_linear, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]


svm_poly <- svm(Outcome ~., data=data_train, kernel="polynomial", coef=1, gamma=1, cost=5)
r <- predict(svm_poly, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]


svm_radial <- svm(Outcome ~., data=data_train, kernel="radial", gamma=1, cost=5)
r <- predict(svm_radial, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]

svm_sigmoid <- svm(Outcome ~., data=data_train, kernel="sigmoid", gamma=1, cost=5)
r <- predict(svm_sigmoid, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]

```

```{r, warning=FALSE, message=FALSE}

# We'll mutate the data_test & data_train to work with the train function
data_test <- data_test %>% mutate(Outcome = as.factor(ifelse(Outcome == 0, 'No','Yes')))
data_train <- data_train %>% mutate(Outcome = as.factor(ifelse(Outcome == 0, 'No','Yes')))

ctrl <- trainControl(method="repeatedcv",
                     number = 5,
                     summaryFunction=twoClassSummary,
                     classProbs=TRUE)

# Grid search to fine tune SVM
grid <- expand.grid(sigma = c(.01, .015, 0.2, 1, 2, 2.5, 3, 4, 5, 10),
                    C = c(0.75, 0.9, 1, 1.1, 1.25, 5, 5.5, 6, 8, 10))

svm.tune <- train(x=data_train[,1:8],
                  y= data_train$Outcome,
                  method = "svmRadial",
                  metric="ROC",
                  preProc=c("center"),
                  tuneGrid = grid,
                  trControl=ctrl)

svm.tune$results %>% filter(sigma == 2)

svm.tune$bestTune
```
```{r}

pred <- predict(svm.tune, data_test[,1:8], type="prob")
p <- ifelse(pred$No > 0.5, 'No', 'Yes')
c <- confusionMatrix(data_test$Outcome, as.factor(p))

c[[2]]
c$overall[[1]]

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
pred_val <-prediction(pred[,2], data_test$Outcome)
perf_val <- performance(pred_val,"auc")
perf_val <- performance(pred_val, "tpr", "fpr")

# Plot the ROC curve
plot(perf_val, col = "green", lwd = 1.5, main="ROC for Radial Kernel SVM")
abline(coef = c(0,1), col="blue", lty=2)
```

