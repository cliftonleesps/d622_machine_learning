---
title: "Predicting Diabetes with Support Vector Machines"
author: "Cliff Lee"
date: "2023-11-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(datasets)
library(caret)
library(e1071)
library(kernlab)
library(pROC)
library(performanceEstimation)
library(ggplot2)
library(GGally)
library(kernlab)
library(tidymodels)
library(doParallel)
library(Metrics)


```


```{r}
min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
  }


```


```{r, warning=FALSE, message=FALSE}
data <- read_csv('diabetes.csv', col_types="nnnnnnnnf")
data <- smote(Outcome ~ ., data, perc.over = 1.5, perc.under = 2.0)

```

### normalize
```{r}
data_2 <- as.data.frame(lapply(data[1:8], min_max_norm))
data <- cbind(data_2, data$`Outcome`)

colnames(data) <- c(colnames(data_2), 'Outcome')
summary(data)



```
```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width="90%"}
#numeric_data <- data %>% dplyr::select(where(is.numeric))
ggpairs(data) 
```

```{r}

set.seed(1234)

sample_set <- sample(nrow(data), round(nrow(data)*0.80), replace = FALSE)

data_train <- data[sample_set,]
data_test <- data[-sample_set,]
```




## Regression

```{r, warning=FALSE, message=FALSE}
# REference: https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html
modelsvm <- svm(Pregnancies ~ Age, data_train)
predict_pregnancies <- predict(modelsvm, data_test)
p <- plot(x=data_test$Age, y=data_test$Pregnancies)
points(data_test$Age, predict_pregnancies, col='red', pch=16)
```


```{r}
rmse_pregnancies <- rmse(data_test$Pregnancies, predict_pregnancies)
paste0("The root mean square error for predicted pregnancies is: " , round(rmse_pregnancies * 100,0), "%.")
```

```{r}
modelsvm <- svm(BloodPressure ~ SkinThickness, data_train)
predict_BloodPressure <- predict(modelsvm, data_test)
plot(x=data_test$SkinThickness, y=data_test$BloodPressure)
points(data_test$SkinThickness, predict_BloodPressure, col='red', pch=16)
```

```{r}
rmse_BloodPressure <- rmse(data_test$BloodPressure, predict_BloodPressure)
paste0("The root mean square error for predicted pregnancies is: " , round(rmse_BloodPressure * 100,0), "%.")
```


```{r, warning=FALSE, message=FALSE}
svm_linear <- svm(Outcome ~., data=data_train, kernel="linear", cost=120)
r <- predict(svm_linear, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]


svm_poly <- svm(Outcome ~., data=data_train, kernel="polynomial", coef=1, gama=1, cost=120)
r <- predict(svm_poly, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]


svm_radial <- svm(Outcome ~., data=data_train, kernel="radial", gama=1, cost=120)
r <- predict(svm_radial, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]

svm_sigmoid <- svm(Outcome ~., data=data_train, kernel="sigmoid", gama=1, cost=120)
r <- predict(svm_sigmoid, data_test)
c <- confusionMatrix(r, data_test$Outcome)
c$overall[[1]]

```

```{r}

# We'll mutate the data_test & data_train to work with the train function
data_test <- data_test %>% mutate(diabetic = as.factor(ifelse(Outcome == 0, 'No','Yes')))
data_train <- data_train %>% mutate(diabetic = as.factor(ifelse(Outcome == 0, 'No','Yes')))

ctrl <- trainControl(method="cv",
                     number = 2,
                     summaryFunction=twoClassSummary,
                     classProbs=TRUE)

# Grid search to fine tune SVM
grid <- expand.grid(sigma = c(.01, .015, 0.2, 1, 2, 2.5, 3, 4, 5, 10),
                    C = c(0.75, 0.9, 1, 1.1, 1.25, 5, 8, 10)
)

svm.tune <- train(x=data_train[,1:8],
                  y= data_train$diabetic,
                  method = "svmRadial",
                  metric="ROC",
                  tuneGrid = grid,
                  trControl=ctrl)

svm.tune$results %>% filter(sigma == 2)

svm.tune$bestTune
```
```{r}

pred <- predict(svm.tune, data_test[,1:8], type="prob")
p <- ifelse(pred$No > 0.5, 'No', 'Yes')
c <- confusionMatrix(data_test$diabetic, as.factor(p))

c[[2]]
c$overall[[1]]

```



### SVM 1 – Tuning Penalty Function
```{r, warning=FALSE, message=FALSE}
# Reference - https://fahadtaimur.wordpress.com/2020/07/19/tuning-svm-in-r-2/

# Define the tuning specification
tuning_specs <- svm_poly(
  cost = tune(), degree = 1
) %>%
  set_mode("classification") %>%
  set_engine("kernlab"); tuning_specs

# Define a grid to vary cost
svm_grid <- expand.grid(cost = c(1, 5, 10, 15, 50, 100, 120, 150)); svm_grid


# Perform cv splits on training data
cv_folds <- vfold_cv(data = data_train, v = 5); cv_folds


# Workflow for tuning
svm_wf <- workflow() %>%
  # add the tuning specificiatons
  add_model(tuning_specs) %>%
  # add the prediction formula
  add_formula(Outcome ~ .)


# Tuning is faster in parallel
all_cores <- parallel::detectCores(logical = FALSE)
cl <- makeCluster(all_cores)
registerDoParallel(cl)


# Start Tuning
svm_results <-  svm_wf %>% 
  tune_grid(resamples = cv_folds,
            grid = svm_grid)


# Collect the results
svm_results %>% 
  collect_metrics() %>%
  arrange(desc(mean))

```

## SVM 1 – Tuning Penalty Function – Visual Analysis

```{r}

svm_results %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(cost = factor(cost)) %>%
  ggplot(aes(cost, mean, color = cost)) +
  geom_point() +
  labs(y = "Accuracy") +
  tidyquant::theme_tq()

```
```{r}
svm_results %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(cost = factor(cost)) %>%
  ggplot(aes(cost, mean, color = cost)) +
  geom_point() +
  labs(y = "AUC") +
  tidyquant::theme_tq()
```
## SVM 1 – Tuning Penalty Function – Finalize

```{r}
# select the best parameter based on auc
svm_results %>%
  select_best(metric = "accuracy") -> svm_final; svm_final

# fit to the train
svm_wf %>%
  finalize_workflow(svm_final) %>%
  fit(data=data_train) -> svm_model

```

## SVM 1 – Tuning Penalty Function – Evaluate

```{r}
 # -- training  
predict(svm_model, data_train, type="prob") %>%
    bind_cols(predict(svm_model, data_train, type="class")) %>%
    bind_cols(.,data_train)-> scored_train 

# -- testing 
predict(svm_model, data_test, type="prob") %>%
      bind_cols(predict(svm_model, data_test, type="class")) %>%
      bind_cols(., data_test) -> scored_test   

# -- AUC: Train and Test 
scored_train %>% 
    metrics(Outcome, .pred_1, estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows(scored_test %>% 
                 metrics(Outcome, .pred_1, estimate = .pred_class) %>%
                 mutate(part="testing") 
    ) %>%
    filter(.metric %in% c("accuracy", "roc_auc")) %>%
    print()

  # -- ROC Charts 
scored_train %>%
  mutate(model = "train") %>%
  bind_rows(scored_test %>%
              mutate(model="test")) %>%
  group_by(model) %>%
  roc_curve(Outcome, .pred_1) %>%
  autoplot() %>%
    print()

```



### SVM 3 – Radial Basis Tuning


```{r, warning=FALSE, message=FALSE}

# Define the tuning specification
tuning_specs <- svm_rbf(cost = 120, rbf_sigma = tune()) %>%
  set_mode("classification") %>%
  set_engine("kernlab"); tuning_specs


## Computational engine: kernlab
# Define a grid to vary cost
svm_grid <- expand.grid(rbf_sigma = c(0.1, 1, 2, 3)); svm_grid

# Perform cv splits on training data
cv_folds <- vfold_cv(data = data_train, v = 5); cv_folds

# Workflow for tuning
svm_wf <- workflow() %>%
  # add the tuning specificiatons
  add_model(tuning_specs) %>%
  # add the prediction formula
  add_formula(Outcome ~ .)


# Tuning is faster in parallel
all_cores <- parallel::detectCores(logical = FALSE)
cl <- makeCluster(all_cores)
registerDoParallel(cl)

# Start Tuning
svm_results <-  svm_wf %>% 
  tune_grid(resamples = cv_folds,
            grid = svm_grid)

# Collect the results
svm_results %>% 
  collect_metrics() %>%
  arrange(desc(mean))

```
### SVM 3 – Radial Basis Function Tuning – Visual Analysis

```{r}

svm_results %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(rbf_sigma = factor(rbf_sigma)) %>%
  ggplot(aes(rbf_sigma, mean, color = rbf_sigma)) +
  geom_point() +
  labs(y = "Accuracy") +
  tidyquant::theme_tq()


```

### SVM 3 – Radial Basis Function Tuning – Visual Analysis


```{r}
svm_results %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(rbf_sigma = factor(rbf_sigma)) %>%
  mutate(rbf_sigma = factor(rbf_sigma)) %>%
  ggplot(aes(rbf_sigma, mean, color = rbf_sigma)) +
  geom_point() +
  labs(y = "AUC") +
  tidyquant::theme_tq()
```


### SVM 3 – Radial Basis Function Tuning – Finalize

```{r}
# select the best parameter based on auc
svm_results %>%
  select_best(metric = "accuracy") -> svm_final; svm_final

# fit to the train
svm_wf %>%
  finalize_workflow(svm_final) %>%
  fit(data=data_train) -> svm_model


```

###SVM 3 – Radial Basis Function – Evaluate


```{r}
# predict on train  
predict(svm_model, data_train, type="prob") %>%
    bind_cols(predict(svm_model, data_train, type="class")) %>%
    bind_cols(.,data_train)-> scored_train 

# predict on test 
predict(svm_model, data_test, type="prob") %>%
      bind_cols(predict(svm_model, data_test, type="class")) %>%
      bind_cols(., data_test) -> scored_test   

# compare train and test auc and accuracy
scored_train %>% 
    metrics(Outcome, .pred_1, estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows(scored_test %>% 
                 metrics(Outcome, .pred_1, estimate = .pred_class) %>%
                 mutate(part="testing") 
    ) %>%
    filter(.metric %in% c("accuracy", "roc_auc")) %>%
    print()

# roc curves
scored_train %>%
  mutate(model = "train") %>%
  bind_rows(scored_test %>%
              mutate(model="test")) %>%
  group_by(model) %>%
  roc_curve(Outcome, .pred_1) %>%
  autoplot() %>%
    print()

```

